{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Block 0A:  Import general purpose packages for ease of use and improved performance."
      ],
      "metadata": {
        "id": "SxMReo5oq986"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "_QYqL8jCvG-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Block 0B:  Import packages for a typical deep learning workflow using TensorFlow and Keras. Import the MNIST image dataset, the IMDB movie review dataset, and the California housing market dataset from Keras."
      ],
      "metadata": {
        "id": "U9gQDgNZvYVo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHxwv0dzNLVD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Block 1:  Load the images in the [MNIST](https://en.wikipedia.org/wiki/MNIST_database) database, rescale intensities from 0 to 255 to 0 to 1, divide the original training dataset into a training dataset and validation dataset, and display a sample of images from the training dataset."
      ],
      "metadata": {
        "id": "4FQ70R3YDnpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the images in the MNIST database.\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Rescale pixel values of images (intensities) from 0 to 255 to 0 to 1.\n",
        "X_train, X_test = X_train/255, X_test/255\n",
        "\n",
        "# Divide the training dataset into a training dataset and a validation\n",
        "# dataset.\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
        "                                                  test_size=0.1,\n",
        "                                                  random_state=42)\n",
        "\n",
        "# Display the first nine images from the training dataset.\n",
        "fig, axs = plt.subplots(3, 3)\n",
        "fig.set_size_inches((7, 7))\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        title = f'actual: {y_train[i*3+j]}'\n",
        "        axs[i,j].imshow(X_train[i*3+j], cmap='gray')\n",
        "        axs[i,j].set_title(title, fontsize=10)\n",
        "        axs[i,j].axis('off')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "u3lfl9Fpuq8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Block 2:  Scale an interval."
      ],
      "metadata": {
        "id": "xAeqgPPUItBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = float(input('Left hand endpoint:  '))\n",
        "x2 = float(input('Right hand endpoint:  '))\n",
        "xrange =\n",
        "xmidpt =\n",
        "\n",
        "\"\"\"\n",
        "sf = float(input('Enter the constrast reduction factor:  '))\n",
        "if sf <= 0 or sf >= 1:\n",
        "    print(f'{sf} is out of range.')\n",
        "else:\n",
        "    dim_range = sf*xrange\n",
        "    x1new = sf*(x1 - xmidpt) + xmidpt\n",
        "    x2new = sf*(x2 - xmidpt) + xmidpt\n",
        "    range_new = x2 - x1\n",
        "    midpt_new = (x1 + x2)/2\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "68QHJJgdIsn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Block 3:  Implement and test a function to reduce contrast of a grayscale image."
      ],
      "metadata": {
        "id": "XCTqOC9pCxCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Replace this comment with your explanation of the purpose of the\n",
        "## following three lines of code.\n",
        "rng = np.random.default_rng()\n",
        "idx = rng.choice(len(X_train))\n",
        "img = X_train[idx]\n",
        "\n",
        "## Replace this comment with your explanation of the purpose of the\n",
        "## following three lines of code.\n",
        "px_min, px_max = np.min(img), np.max(img)\n",
        "range = px_max - px_min\n",
        "midpt = (px_max + px_min)/2\n",
        "\n",
        "## Replace this comment with your explanation of the purpose of the\n",
        "## following code snippet.\n",
        "sf = float(input('Enter the constrast reduction factor:  '))\n",
        "if sf <= 0 or sf >= 1:\n",
        "    print(f'{sf} is out of range.')\n",
        "else:\n",
        "    dim_img = sf*(img - midpt) + midpt\n",
        "    ## Compare the original (left) and altered (right) images visually.\n",
        "    fig, axs = plt.subplots(1, 2)\n",
        "    for i, (title, img_cf) in enumerate(zip(('original', 'altered'),\n",
        "                                            (img, dim_img))):\n",
        "        axs[i].set_title(title, fontsize=10)\n",
        "        axs[i].imshow(img_cf, cmap='gray', vmin=0, vmax=1)\n",
        "    axs[i].axis('off')\n",
        "    fig.show()\n"
      ],
      "metadata": {
        "id": "RPICLAUhuSw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Block 4:  Reduce the contrast of all the images in the MNIST dataset."
      ],
      "metadata": {
        "id": "hhjcCdy1ttzB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rWpEYBNT0gkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Block 5:  Define and compile the model."
      ],
      "metadata": {
        "id": "kOIYnjTo1D-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ezIaunZz7Pj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Block 6:  Train the model."
      ],
      "metadata": {
        "id": "iajbNJLf2nwO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kqX6N09Z7StG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Block 7: Assess the performance of the model and plot the training history as accuracy vs epoch."
      ],
      "metadata": {
        "id": "SuBvSagm2vG4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "49t7ylNk7RFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Block 8:  Predict digits for images in the testing dataset and display a small selection of the predictions."
      ],
      "metadata": {
        "id": "M2FXAAp423VS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VNe0Kk097QRt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}